<html>

<head>
<title>dissertation_fragments</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8">
<style type="text/css">
	body {background-color: #bac0c7}
    p.binderItem {margin: 10.0px 0.0px 0.0px 05.0px; font-family:Cochin, Times, Courier, Arial, serif; font-size:14.0px;}
    .page {border: 1px solid #727272; background: #fff}
    hr {
      border-top: 1px dashed #000;
      border-bottom: 0px solid #fff;
      color: #fff;
      background-color: #fff;
      height: 0px;
  </style>
</head>

<body>

<table border="0" width="100%" cellspacing="3">
<tr>
<td>

<table class="page" width="100%" cellspacing="10" cellpadding="2">
<tr>
<td valign="top">

<ul>
<li>
<p class="binderItem"><strong>Abstract</strong><br/><br/>
<!--<br/>
\topmatter{Abstract}<br/>
--><br/>
<br/>
In many real-world environments such as flooded pipes or caves, exteroceptive sensors, such as vision, range or touch, often fail to give any useful information for robotic tasks.  This may result from complete sensor failure or incompatibility with the ambient environment.  We investigate how proprioceptive sensors can help robots to successfully explore, map and navigate in these types of challenging environments.<br/>
<br/>
Our approach is to use a snake robot with propr...</p>
</li>
<li>
<p class="binderItem"><strong>First Paragraph</strong><br/>#Introduction<br/>
<br/>
 In this dissertation, we develop an algorithmic approach for robotically mapping confined environments using internal sensors only.  Some challenging environments such as underground caves and pipes are impossible to explore and map with external sensors.  Such environments often cause external sensors to fail because they are too confined, too hostile for the sensors, or incompatible to the fluid medium.  These environments are also impossible for humans to explore for similar r...</p>
</li>
<hr/>
<ul>
<li>
<p class="binderItem"><strong>Motivations</strong><br/>For example, an approach that is invariant to ambient fluid (air, water, muddy water, etc.) would significantly impact cave exploration and underground science by the access to still deeper and smaller cave arteries regardless of whether they are submerged in water.  Search and rescue operations would have additional tools for locating survivors in complicated debris piles or collapsed mines.  Utility service workers would be able to map and inspect pipe networks without having to excavate or ev...</p>
</li>
<li>
<p class="binderItem"><strong>Challenges</strong><br/>## Challenges <br/>
<br/>
###Limitations of Exteroceptive Sensors<br/>
<br/>
Exteroceptive sensors are sensors that are affixed externally and designed to sense information about the robot's environment.  They're biological equivalents include such things as vision, hearing, touch, taste and smell.  The robot equivalents include touch, cameras, sonar, and laser range-finders.<br/>
<br/>
Currently we cannot effectively explore and map these environments with exteroceptive sensors.  Current state-of-the-art mapping methods dep...</p>
</li>
<li>
<p class="binderItem"><strong>Related Work</strong><br/>##Related Work<br/>
<br/>
The mapping of confined spaces is a recurring theme in the research literature.  Work has been done to navigate and map underground abandoned mines [Thrun04] with large wheeled robots traveling through the constructed corridors.  Although the environment is large enough and clear enough to make use of vision and range sensors, its location underground makes the use of GPS technologies problematic.  This work can be applied to confined environments where exteroceptive sensors are ...</p>
</li>
<li>
<p class="binderItem"><strong>Approach</strong><br/>##Approach<br/>
<br/>
To address these challenges, our approach is to develop algorithmic methods for utilizing proprioceptive joint angle information on an articulated mobile robot to enable exploration and mapping of a confined environment.  From a series of complete posture information sets, we build up void space information into a posture image and integrate it into a whole map.  We hypothesize that with the posture images taken at multiple robot poses in the environment, we can integrate them into a...</p>
</li>
<hr/>
<ul>
<li>
<p class="binderItem"><strong>draft Experimental System</strong><br/>##Experimental System<br/>
<br/>
Robot setup, joints and geometry, environmental parameters, simulation.<br/>
<br/>
We explicitly chose to develop our approach in a simulation environment in order to rapidly develop a theoretical framework to the problem of mapping without external sensing.  In future work, we will apply these techniques to physical robots.<br/>
<br/>
We choose to use the Bullet physics engine (version 2.77) because it is free, open source, mature, and actively developed.  Though it is primarily designed for...</p>
</li>
</ul>
</ul>
<hr/>
<li>
<p class="binderItem"><strong>Sensing Space</strong><br/>#Sensing Space [chap:sensing]</p>
</li>
<hr/>
<ul>
<li>
<p class="binderItem"><strong>rationale</strong><br/>## Problem [sensing:problem]<br/>
<br/>
Need to argue here that we are forced to use a contact sensing modality.  However, existing contact sensing solutions only return contact point data, i.e. point and location of the boundary.  Whereas, with range-based solution, both boundary and void space information are returned.  Mostly void space in fact.<br/>
<br/>
Types of sensing can be classified with the following table.  The biological senses are grouped with their analogous robotics counterparts.<br/>
<br/>
<!--<br/>
<br/>
\begin{cent...</p>
</li>
<li>
<p class="binderItem"><strong>void space</strong><br/><br/>
## How to Sense<br/>
<br/>
We use a common sense assumption that the robot's body can never intersect with an obstacle.  We call this the Obstacle-Exclusion Assumption.  If we take the corollary of this assumption, we conclude that all space that intersects with the robot's body must be free space.  If we record the robot's body posture over time, we can use this to build a map of the local environment's free space.<br/>
<br/>
We need 3 key ingredients to build an accurate map of the free space in the local enviro...</p>
</li>
<li>
<p class="binderItem"><strong>posture image</strong><br/>## Posture Image<br/>
<br/>
Using the control method shown in Control chapter to sweep out the void space of the local environment, we show how we capture sensor data and process it for consumption for our later mapping algorithms.<br/>
<br/>
###Data Capture<br/>
<br/>
Once the posture of the snake has stabilized and the anchor points give us good reference poses to the global frame, our objective is take the posture vector, \\(\bar{\phi_t}\\) at time \\(t\\), and convert it to a 2D spatial representation of free space, \\(M...</p>
</li>
<li>
<p class="binderItem"><strong>convex hull</strong><br/><br/>
## Data Processing<br/>
<br/>
Once we have the raw sensor data successfully plotted into a local occupancy map, we must convert this data into a form that is useful for our mapping algorithms.  Here, we present three different forms of data processing that we use in our approach.<br/>
<br/>
###Convex Hull<br/>
<br/>
One way we process our free space data is by taking its convex hull.  In theory, this would create some smooth boundaries and can plausibly represent the true local space under some certain conditions.   The def...</p>
</li>
<li>
<p class="binderItem"><strong>alpha shape</strong><br/><br/>
###Alpha Shape<br/>
<br/>
An alternative to the convex hull is the alpha shape \cite{Edelsbrunner:1983p772}.  Like the convex hull, it creates a polygon or polygons that contain all the points.  Unlike the convex hull, it can construct a containing polygon with concave or even hole features.  <br/>
<br/>
![Alpha Shape example from \cite[cgal:d-as2-12b]][alpha_cgal]<br/>
<br/>
[alpha_cgal]: alphashape.png width=400px<br/>
<br/>
To construct the alpha shape, first we choose a radius \\(r\\) for a circle \\(C\\).  Next, if a pair of poi...</p>
</li>
<li>
<p class="binderItem"><strong>medial axis</strong><br/><br/>
<br/>
###Medial Axis<br/>
<br/>
Although polygons that represent the sweeped free space are useful, we need something that is more compact that also filters out the smoothing effects of blind spots and sharp features.  That is, we want an approach where the negative effects of missing data, erroneous data, and loss of salient features are minimized.<br/>
<br/>
For this purpose, we compute the medial axis, also sometimes known as thinning or skeletonization [cite].  This concept takes a shape and reduces it to a path or...</p>
</li>
<li>
<p class="binderItem"><strong>slip prevention</strong><br/><br/>
## Managing Slip<br/>
<br/>
Since the possibility of error occurring in our free space maps is very real and has the consequences of making the data near-useless, we want to do all we can to prevent and mitigate any failure conditions.  As the primary source of error is anchor slip, we do all we can to focus on this issue while probing the environment.  We use a number of techniques for both prevention and detection of error.  We describe all of our approaches below.<br/>
<br/>
###Slip Prevention<br/>
<br/>
We have 6 strate...</p>
</li>
<li>
<p class="binderItem"><strong>averaging ref poses</strong><br/><br/>
####Averaging Reference Poses<br/>
<br/>
For our fourth strategy, when actually using the reference poses to compute the position of the snake in our local free space map, we want to use as many of the reference poses as possible while filtering out any errors that would occur from possible pathological cases.   If just one reference pose is erroneous and we use that reference pose to compute position of the snake in free space,  it will severely damage our results.  We want to mitigate the possibility o...</p>
</li>
<li>
<p class="binderItem"><strong>separation of sweep maps</strong><br/><br/>
####Separation of Sweep Maps<br/>
<br/>
Our fifth and final strategy for preventing errors in our sensor maps is to divide the forward sweep phase and backward sweep phase into separate maps.  From our experiments, we determined that a consistent source of error occurs when switching the anchoring responsibility from the back half of the snake to the front half.  The series of events of retracting the front half of the snake to anchors and extending the back half for sweeping tends to cause some disconti...</p>
</li>
<li>
<p class="binderItem"><strong>root pose adjustment</strong><br/><br/>
###Slip Mitigation<br/>
<br/>
In the case that error is introduced into our local free space map, we are interested in mitigating its negative effects.   We have developed two approaches for handling error when it occurs during sensing.<br/>
<br/>
Since we start our mapping process by determining the global pose of the local origin \\(P_{19}\\), error occurs when \\(P_{19}\\) is no longer in its proper place.  Either it moves by translation or more commonly and critically, it experiences rotational error.  <br/>
<br/>
####R...</p>
</li>
</ul>
<hr/>
<li>
<p class="binderItem"><strong>Environmental Landmarks</strong><br/>#Environmental Landmarks [chap:landmarks]</p>
</li>
<hr/>
<ul>
<li>
<p class="binderItem"><strong>Problem</strong><br/><br/>
How to build features and landmarks from void space data?  Need to build a map and localize against.  Most feature techniques use boundary information as primitives for environmental features.  Need approach that uses only void space.<br/>
<br/>
<br/>
Features to build the map<br/>
<br/>
Boundary features<br/>
Obstacles/walls<br/>
Corners<br/>
<br/>
Void space features<br/>
Shape features<br/>
Spatial features</p>
</li>
<li>
<p class="binderItem"><strong>Features of Environment</strong><br/>Landmark features to track environment, difficult using only proprioceptive sensing</p>
</li>
<li>
<p class="binderItem"><strong>Corner Examples and Results</strong><br/>Corner features extracted from posture image, much difficulties</p>
</li>
<li>
<p class="binderItem"><strong>Wall Detection</strong><br/>Detect and measure the wall, time-consuming and sparse.</p>
</li>
<li>
<p class="binderItem"><strong>Different Macro Features</strong><br/>1) anchor points spline, 2) polygon walls, 3) medial axis</p>
</li>
<li>
<p class="binderItem"><strong>Spatial Curve</strong><br/>Shape of the sensed void space in local environment should give us information.<br/>
How can we extract this information and represent it in an useful way?<br/>
<br/>
Spatial curve ct = scurve(It) where It is posture image<br/>
Smoothed version gives us a curve representation of the local space<br/>
<br/>
</p>
</li>
<hr/>
<ul>
<li>
<p class="binderItem"><strong>Macro Feature Extraction</strong><br/>postureimage->alpha shape->medial axis</p>
</li>
<li>
<p class="binderItem"><strong>Pipe Shape, Macro Feature</strong><br/>Use general shape of environment, can be approximated with sparse data</p>
</li>
</ul>
<hr/>
<li>
<p class="binderItem"><strong>Spatial Features</strong><br/>3 different spatial features from posture images<br/>
blooms<br/>
arches<br/>
bends<br/>
Landmarks usually indicate junctions or gaps in space<br/>
Can match landmarks together to improve the map<br/>
<br/>
<br/>
<br/>
<br/>
<br/>
<br/>
</p>
</li>
</ul>
<hr/>
<li>
<p class="binderItem"><strong>Defining Position</strong><br/>#Defining Position [chap:position]</p>
</li>
<hr/>
<ul>
<li>
<p class="binderItem"><strong>rationale</strong><br/>##Problem [position:problem]<br/>
<br/>
<br/>
<br/>
Now that our snake robot is capable of moving through the environment with the adaptive concertina gait behavior, we need some way of estimating how far it is moving and in which direction.<br/>
<br/>
As we established earlier, we have no external sensors because we assume their failure from environmental conditions.  We cannot rely on GPS since it is not effective underground or in pipes.  We do not have wheeled shaft encoders since we have no wheels and do not expect to a...</p>
</li>
<li>
<p class="binderItem"><strong>anchoring and slip</strong><br/><br/>
<br/>
Our proprioceptive approach achieves motion estimation by anchoring multiple points of the body with the environment and kinematically tracking the change in distance between the immobilized parts as the snake contracts and extends.  This gives us a motion estimation method that only depends on the joint sensors.  We show the effectiveness in a series of experiments.<br/>
 <br/>
<br/>
##Immobilizing the Anchors [sec:anchors]<br/>
<br/>
<br/>
<!--<br/>
%-Immobilize anchors to create global references<br/>
%-Conditions when immobility...</p>
</li>
<li>
<p class="binderItem"><strong>poses of rigid bodies on snake</strong><br/><br/>
<br/>
##Tracking Motion<br/>
<br/>
<!--<br/>
%-What a reference is<br/>
%-each active reference can be used to compute the pose of the snake at that given time<br/>
%-active references may disagree with each other<br/>
%-take current oldest active reference to compute current pose<br/>
%-How to create new references (kinematic computation)<br/>
%-When to deactivate references (violation of local/pre stability)<br/>
%-Loss of all references recovery<br/>
--><br/>
<br/>
In order to track motion through the environment, we need to establish our mathematical fra...</p>
</li>
<li>
<p class="binderItem"><strong>computing stable ref poses</strong><br/><br/>
###Reference Poses<br/>
<br/>
A reference pose is the position and orientation of a rigid body segment that has been immobilized with respect to the global frame.  A reference pose is valuable because it gives a fixed reference point to the global environment and allows us to track the motion of the rest of the robot.   Special care must be taken to ensure that when using a reference pose, the rigid body it's attached to is truly immobilized.<br/>
<br/>
A reference pose is either active or inactive.  A reference i...</p>
</li>
<li>
<p class="binderItem"><strong>posture curve and posture frame</strong><br/><br/>
##Robot-Centered Coordinate Frame [sec:GPAC]<br/>
<br/>
<!--<br/>
%-N possible local coordinate systems in snake<br/>
%-none are very good to represent pose of snake because of the high variance in orientation.  Try to relate two poses to each other, orientation has almost no correlation<br/>
%-orientation is also primary source of error<br/>
%-prefer a coordinate system that represents the gross posture and pose of snake.  COM can sometimes be out of body<br/>
%-GPAC pose proposed.<br/>
--><br/>
<br/>
Though we now have a local coordinate fra...</p>
</li>
</ul>
<hr/>
<li>
<p class="binderItem"><strong>Control and Locomotion</strong><br/>#Control and Locomotion [chap:control]<br/>
<br/>
Simulated robot control<br/>
algorithms tuned for simulated environment<br/>
Adaptive anchoring<br/>
making strong and stable anchors to the walls with verification<br/>
Concertina locomotion<br/>
Practical heuristic for sensor-deprived environment<br/>
Snake control, backbone curves (Chirikjian)<br/>
inverse kinematics by fitting to a curve<br/>
Segmented behaviors<br/>
sections of linkage controlled by different behaviors<br/>
Smooth motion and compliance<br/>
interpolated and compliant motion<br/>
Stability dete...</p>
</li>
<hr/>
<ul>
<li>
<p class="binderItem"><strong>Control Methodology</strong><br/>##Control Methodology<br/>
<br/>
Backbone curve fitting, IK method, segmented behaviors</p>
</li>
<li>
<p class="binderItem"><strong>Behaviors</strong><br/>##Behaviors [control:behaviors]<br/>
<br/>
Locomotion steps, extensions, path-following, anchoring</p>
</li>
<li>
<p class="binderItem"><strong>biological concertina</strong><br/><br/>
##Problem [control:problem]<br/>
<br/>
FIXME: Related work and our contrasted difference.  What can we achieve that others cannot.  Why is our approach better for this particular case?  <br/>
<br/>
In order to successfully control a snake robot and have it move through the environment, we need a solution for locomotion, motion planning, and handling collisions.  Since we have no exteroceptive sensors, this makes the problem challenging.  The robot is unable to sense what is right in front of it and must move blind...</p>
</li>
<li>
<p class="binderItem"><strong>backbone curve fitting</strong><br/><br/>
For both of these requirements, we use the backbone curve-fitting methodology first described by \cite{Chirikijan:1995p774}.  This method of control is to produce a parameterized curve that represents the desired posture of the snake over time. Over time the curve changes to reflect desired changes in the snake posture. Snake backbone curve fitting is achieved by finding the joint positions that best fit the snake body onto the curve. This is found either by direct calculation or a search algor...</p>
</li>
<li>
<p class="binderItem"><strong>adaptive anchoring</strong><br/><br/>
##Anchoring<br/>
<br/>
In order to fit the anchor points to a pipe of unknown width, we need some way of sensing the walls.  Since we have no exteroceptive sensors, the best way of sensing the width of the walls is by contact.  Since we have no direct contact sensor per se, we must detect contact indirectly through the robot's proprioceptive joint sensors.<br/>
<br/>
Using the backbone curve fitting approach, we take one period of a sine curve as the template form we wish the robot to follow.  We then modify this ...</p>
</li>
<li>
<p class="binderItem"><strong>behavior architecture</strong><br/><br/>
## Behavior Architecture<br/>
<br/>
Our method of control is a behavior-based architecture that is charged with reading and tasking the servo-based motor controllers of each joint.  Each behavior may be a primitive low-level behavior or a high-level composite behavior composed of multiple sub-behaviors.  Furthermore, a behavior may have complete control of every joint on the snake or the joints may be divided between different but mutually supporting behaviors.  This architecture allows us to achieve a h...</p>
</li>
<li>
<p class="binderItem"><strong>smooth motion</strong><br/><br/>
##Smooth Motion [sec:smooth]<br/>
<br/>
We desire the motion of our snake robot to be slow and smooth in nature.  It does us no benefit for the motion to be sudden and jerky.  Moments of high acceleration can have unintended consequences that result in our anchor points slipping.  Either collisions with the environment or transient internal dynamics can cause the anchor points to slip.<br/>
<br/>
Our method of ensuring smooth motion is to take the initial and target posture of the joints of the snake, perform line...</p>
</li>
<li>
<p class="binderItem"><strong>behavior merging</strong><br/><br/>
##Behavior Merging [sec:merge]<br/>
<br/>
<br/>
There are a few methods for merging behaviors that overlap in some way.  One way of the previous section is for two behaviors to overlap temporally and using the HoldTransition behavior to handle a smooth transition from one configuration to another.<br/>
<br/>
In the event that two behaviors control adjacent sets of joints or overlap their control in some way, a conflict resolution is method is needed to not only select the proper command for contested joints, but to pre...</p>
</li>
<li>
<p class="binderItem"><strong>compliant motion</strong><br/><br/>
##Compliant Motion<br/>
<br/>
In the previous section, we mentioned compliance but not our implementation.  Compliant motion is a much used technique in robotics and has been discussed widely (cite).  The two approaches are either passive or active compliance.  Our approach is to use passive compliance since we have no means to detect contact or sense obstacles.<br/>
<br/>
Passive compliance is achieved by changing the settings on the max torque parameter of each joint's servo controller.  We use a high setting fo...</p>
</li>
<li>
<p class="binderItem"><strong>stable motion</strong><br/><br/>
##Stability Assurance [sec:stability]<br/>
<br/>
In a previous section on smooth motion, we discussed an interpolation technique to smoothly transition from one posture to another.  The primary motive of this was to keep the parts of the snake body that are immobilized from being destabilized by transient forces and causing anchor slip.  Static forces from prolonged pushing against an obstacle or wall are a separate matter.<br/>
<br/>
For a pose transition that has a sufficiently large number of interpolation step...</p>
</li>
<li>
<p class="binderItem"><strong>adaptive concertina gait</strong><br/><br/>
##Adaptive Step<br/>
<br/>
<!--<br/>
%Show the behavior sequence in high-level terms.  Show graphics.<br/>
<br/>
%Explain each behavior step in terms of the concepts we already learned.<br/>
--><br/>
<br/>
Using these tools at our disposable, we can now build a suitable locomotion behavior for an unknown pipe with no exteroception.  The entirety of our designed behavior is shown in [](#adaptive_step) and is called the adaptive concertina gait, a biologically-inspired gait based on the concertina gait but modified for the change in se...</p>
</li>
<li>
<p class="binderItem"><strong>snake to environment analysis</strong><br/><br/>
##Analysis<br/>
<br/>
<br/>
Our theoretical contribution is a quantitative analysis of the trade-space between environmental characteristics, snake robot morphology, and locomotion control parameters.  That is, given a snake robot morphology and control parameters, what types of environments can we successfully explore.  Conversely, given a specific environment, what robot morphology and control parameters are required to successfully explore it.<br/>
<br/>
First we will perform an analysis of the trade-space for formi...</p>
</li>
<li>
<p class="binderItem"><strong>sensing behavior</strong><br/><br/>
## Sensing Behavior<br/>
<br/>
In order to capture as much information about the environment as we can, we need to sweep the robot's body around as much as possible while trying to cover as much space as possible without losing our reference pose to the global frame.  Therefore, we have devised a behavior assemblage that separates responsibility for anchoring on one half of the snake and for probing the environment with the other.  This assemblage is shown in [](#pokewalls1).  The resulting behavior is s...</p>
</li>
</ul>
<hr/>
<li>
<p class="binderItem"><strong>Building Maps</strong><br/>#Building Maps [chap:maps]</p>
</li>
<hr/>
<ul>
<li>
<p class="binderItem"><strong>Problem</strong><br/>Challenges of build map.  Given features and actions, why existing methods are not sufficient for current problem</p>
</li>
<li>
<p class="binderItem"><strong>Naive Method</strong><br/>using only last pose to estimate location using spatial curve</p>
</li>
<hr/>
<ul>
<li>
<p class="binderItem"><strong>overlap function</strong><br/>Correct transform between poses by ICP on medial axis</p>
</li>
<li>
<p class="binderItem"><strong>generalized ICP</strong><br/>general ICP, curve algorithms for naive method</p>
</li>
<li>
<p class="binderItem"><strong>constraints</strong><br/>### Constraints<br/>
<br/>
Now that we have fully defined our overlap function, there are two types of constraints we can make with this function:   the *in-place constraint* and the *step constraint*.  <br/>
<br/>
The in-place constraint, shown in [](#inplace_constraint), performs an overlap with two collocated poses that separate the forward and backward sweeping behavior.  Given pose \\(X_k\\), find pose \\(X_{k+1}\\):<br/>
<br/>
<!--<br/>
\begin{equation}<br/>
X_{k+1} = \mathrm{overlap}(X_k, I_k, I_{k+1}, \varnothing)<br/>
\end{equatio...</p>
</li>
<li>
<p class="binderItem"><strong>Results</strong><br/>results of naive method for single path pipes</p>
</li>
</ul>
<hr/>
<li>
<p class="binderItem"><strong>Axis Method</strong><br/>challenges of backtracking, how naive method only uses last pose and is insufficient for backtracking.  Need to use whole history to follow past map</p>
</li>
<hr/>
<ul>
<li>
<p class="binderItem"><strong>generating axis</strong><br/>###Generating the path [gen_axis]<br/>
<br/>
![Computing Axis from Union of Posture Images][global_medial_axis]<br/>
<br/>
[global_medial_axis]: global_medial_axis width=400px<br/>
<br/>
<br/>
We define the axis to be the medial axis of the union of the globally situated alpha shapes of the posture images.  The axis is computed from a collection of poses that represent the past robot's trajectory.  <br/>
<br/>
The topology of an axis is computed from the union of all of the poses' alpha shapes.  The union of the alpha shapes is populated w...</p>
</li>
<li>
<p class="binderItem"><strong>overlap_axis function</strong><br/>### OverlapAxis Function [sec:overlapAxis]<br/>
<br/>
Now that we have axis computed from the union of alpha shapes of posture images, new poses can now be constrained to the axis.  In the event that the robot backtracks, it will utilize the full history of robot's poses to localize the robot's new position.<br/>
<br/>
We define a new function similar to **overlap**, called **overlapAxis**, that functions the same way as the overlap function.  However, instead of overlapping spatial curves with spatial curves, it o...</p>
</li>
<li>
<p class="binderItem"><strong>Results</strong><br/>Results of axis method for single path pipes</p>
</li>
</ul>
</ul>
<hr/>
<li>
<p class="binderItem"><strong>Mapping with Junctions</strong><br/>#Mapping with Junctions [chap:junctions]</p>
</li>
<hr/>
<ul>
<li>
<p class="binderItem"><strong>Problem</strong><br/>axis method insufficient for maps with junctions.  Structures are undefined. How to ICP a tree instead of a curve? Need generalized solution for arbitrary amounts of "branches"</p>
</li>
<li>
<p class="binderItem"><strong>Junction Method</strong><br/>## Junction Method<br/>
<br/>
The approach we use to handle junctions in the environment is called the **junction method**.  We first need to introduce a new map representation.</p>
</li>
<hr/>
<ul>
<li>
<p class="binderItem"><strong>Skeleton Mapping</strong><br/>Each shoot is path graph, with two leaves.  Except for root, all shoots have origin from a parent shoot at the branch point</p>
</li>
<li>
<p class="binderItem"><strong>Generating Skeletons</strong><br/>Basic algorithm to generate medial axis of each shoot set, and cut the medial axis to create the shoots.</p>
</li>
<li>
<p class="binderItem"><strong>Adding Poses to Skeletons</strong><br/>### Adding New Poses to Skeleton Map [junction:add_to_skeleton]<br/>
<br/>
Now that we have described how to generate a skeleton given a set of data, we need to explain how we go about adding new poses to a map.  In the base case, the first two poses are added to the initial skeleton.  The initial skeleton then becomes the root skeleton and ancestor to all future skeletons.  A skeleton map can have one or more skeletons.  We explain how to add a pose to a single skeleton map and then explain how to add a ...</p>
</li>
<li>
<p class="binderItem"><strong>Results</strong><br/><br/>
### Algorithm<br/>
<br/>
The pseudocode describing the axis method mapping approach is shown in algorithm [](#alg:junction_method).  The portion to estimating the motion of all possible splices on the skeleton map is in algorithm [](#alg:motion_skeletons).  The portion devoted to adding the pose to the right skeleton is in algorithm [](#alg:add_skeletons).  The portion regarding generating the skeleton is in algorithm [](#alg:gen_skeletons).<br/>
<br/>
<!--<br/>
\begin{algorithm}<br/>
\caption{Junction Method}       <br/>
\label...</p>
</li>
</ul>
</ul>
<hr/>
<li>
<p class="binderItem"><strong>Searching for the Best Map</strong><br/>#Searching for the Best Map [chap:search]</p>
</li>
<hr/>
<ul>
<li>
<p class="binderItem"><strong>Problem</strong><br/>## Problem [search:problem]<br/>
<br/>
Though we have shown how to build a map with junctions in the environment, there are a number of ways for error to be injected into the map.  In particular, we identify three possible ways for error to be added.<br/>
<br/>
The first is that there is error in the pose of the robot.  In this case, a combination of the last best pose and the current estimated pose gives a pathological estimation of the location and orientation of the robot.  This could have innocuous results in s...</p>
</li>
<li>
<p class="binderItem"><strong>Search Method</strong><br/>## Search Method<br/>
<br/>
The *search method* is trying to estimate and optimize the consistency of the map defined by the following parameters: 1) \\(X_{0:t}\\), the global poses of the robot, 2) \\(S_{0:m}\\), the skeletons and their member poses, and 3) \\(b_{1:m}\\), the spatial transform between parent and child skeletons.  Finding the best map would involve making sure the poses are classified to their appropriate skeletons, the poses are placed so that their spatial curves are mutually overlappin...</p>
</li>
<hr/>
<ul>
<li>
<p class="binderItem"><strong>Parameterization</strong><br/>### Parameterization<br/>
<br/>
In order to perform a search of the best map, we need to define the parameters of the map we will be searching over.  The ultimate goal is to search for the best possible values of \\(X_{1:t}\\) to produce the most consistent map given the posture image observations of \\(I_{1:t}\\) and the actions \\(A_{1:t}\\).<br/>
<br/>
To restate the experience of the robot, we have a series of actions:<br/>
<br/>
<!--<br/>
\begin{equation}<br/>
    A_t = <br/>
\begin{cases}<br/>
    f, & \text{forward locomotion step}\\<br/>
   ...</p>
</li>
<li>
<p class="binderItem"><strong>Motion Estimation</strong><br/><br/>
### Motion Estimation<br/>
<br/>
Given the initial distribution of poses shown in [](#init_pose_distribution), we want to first model the movement of the robot given the current action A_t.  For every candidate pose shown in [](#init_pose_distribution), motion is achieved by displacing the pose by a fixed distance along the curve of each of the splices the pose is contained on.  The fixed distance displaced is an empirically determined value from the average locomotion distance of the robot.  For our cur...</p>
</li>
<li>
<p class="binderItem"><strong>Add to Skeleton Map</strong><br/><br/>
### Add to Skeleton Map<br/>
<br/>
This phase of the *search method* is identical to [](#junction:add_to_skeleton).  In this case, we use the best pose selected from the motion estimation phase.  If the spatial curve is diverging, we create a new skeleton.  If it is not, we add it to an existing skeleton.<br/>
</p>
</li>
<li>
<p class="binderItem"><strong>Overlapping Skeletons</strong><br/><br/>
### Overlapping Skeletons<br/>
<br/>
The next phase of the *junction method* is to maximize the overlap of the skeletons.  That is, we will adjust the transform between parent and child skeletons such that they are aligned and create junctions that are consistent with the observations.<br/>
<br/>
Given a parent-child skeleton pair, like the motion estimation phase, we discretize the possible locations of the control point on the parent.  That is, we select a handful of possible locations for the child frame to be ...</p>
</li>
<li>
<p class="binderItem"><strong>Localization</strong><br/><br/>
### Localization<br/>
<br/>
ICP localize all previous samples across all splices<br/>
Select maximum evaluated pose H(x)<br/>
H(x) = normLandmarkSum * contigFrac0 * contigFrac1<br/>
Correct the map with best fit pose<br/>
<br/>
<br/>
<br/>
![Localization: ICP of initial poses and selection of best pose.][localization_evaluation]<br/>
<br/>
[localization_evaluation]: localization_evaluation width=400px<br/>
<br/>
![Localization: ICP of initial poses and selection of best pose.][localization_cost]<br/>
<br/>
[localization_cost]: localization_cost width=400px<br/>
<br/>
<br/>
Immediate...</p>
</li>
<li>
<p class="binderItem"><strong>Merge Skeletons</strong><br/><br/>
### Merge Skeletons<br/>
Merge skeletons together if they are fully constrained<br/>
<br/>
<br/>
![Skeletons before merge.][skeleton_premerge]<br/>
<br/>
[skeleton_premerge]: skeleton_premerge width=300px<br/>
<br/>
![Skeletons after merge.][skeleton_postmerge]<br/>
<br/>
[skeleton_postmerge]: skeleton_postmerge width=300px<br/>
<br/>
<br/>
</p>
</li>
</ul>
</ul>
<hr/>
<li>
<p class="binderItem"><strong>Experiments</strong><br/># Experiments</p>
</li>
<hr/>
<ul>
<li>
<p class="binderItem"><strong>Experimental Setup</strong><br/>##  Experimental Setup</p>
</li>
<li>
<p class="binderItem"><strong>Results</strong><br/>## Results [experiment:results]<br/>
<br/>
The results as they stand.  WE earlier presented videos showing one-off examples of successful mapping.  Each of the maps was built in controlled conditions with parameters that were specifically tuned to the particular feature of the map.<br/>
<br/>
In our desire to make a more unified mapping approach, a generalized algorithm is not as successful for individual maps, but produces mediocre results over all.  Frequently the robot fails to map the environment correctly beca...</p>
</li>
</ul>
<hr/>
<li>
<p class="binderItem"><strong>Conclusion</strong></p>
</li>
<hr/>
<ul>
<li>
<p class="binderItem"><strong>Conclusion</strong><br/>## Conclusion<br/>
<br/>
Foo</p>
</li>
</ul>
</ul>

</td>
<td width="8">
</td>
</tr>
</table>

</td>
</tr>
</table>

</body>
</html>