{\rtf1\ansi\ansicpg1252\cocoartf1187\cocoasubrtf400
{\fonttbl\f0\fnil\fcharset0 Cochin;}
{\colortbl;\red255\green255\blue255;}
\pard\tx720\tx1440\tx2160\tx2880\tx3600\tx4320\fi360\sl288\slmult1\pardirnatural

\f0\fs28 \cf0 \
## How to Sense\
\
We use a common sense assumption that the robot's body can never intersect with an obstacle.  We call this the Obstacle-Exclusion Assumption.  If we take the corollary of this assumption, we conclude that all space that intersects with the robot's body must be free space.  If we record the robot's body posture over time, we can use this to build a map of the local environment's free space.\
\
We need 3 key ingredients to build an accurate map of the free space in the local environment:  1) known geometry of the robot's rigid body linkages, 2) accurate joint sensors for computing kinematics, and 3) an accurate reference pose to the global frame.  If all of these things are available, we can build a local map such as shown in  [](#pokeBehavior).\
\
\
![TODO: Remove the obstacle map.  Free space map from PokeWalls behavior.][pokeBehavior]\
\
[pokeBehavior]: {\field{\*\fldinst{HYPERLINK "scrivlnk://152"}}{\fldrslt PokeBehavior.png}} width=400px\
\
\
The map is achieved by rigidly anchoring to the environment and maintaining a set of stable reference poses.  One side of the snake's body is used to sweep the free space, making multiple snapshots of the robot's posture over time and plotting them into a map.  We discuss each aspect of our approach and show the results for a variety of environmental configurations.\
\
The key point here is that sensing cannot be accomplished without action.  Action by itself runs the risk of disturbing the environment or causing errors in the reference pose.  Though sensing cannot be accomplished without action, action runs the risk of modifying the result.  Special care must be taken that the risk of modifying the environment is minimized.  Here, we include the robot's body in our definition of the environment so that anchor slippage is a form of environment modification.\
\
As part of the action, at each instance of time \\\\(t\\\\), we produce a posture vector \\\\(\\bar\{phi\}_t\\\\), representing the state of the joint angle sensors of the robot such that:\
\
<!--\
\\begin\{eqnarray\}\
\\bar\{\\phi\}_t = \{ \\phi^t_1, \\phi^t_2, \'85 , \\phi^t_\{M-1\}, \\phi^t_M\}\
\\end\{eqnarray\}\
-->\
\
Over a series of time, we produce a series of posture vectors called the posture sequence:\
\
<!--\
\\begin\{eqnarray\}\
\\bar\{\\Phi\}_\{1:t\} = \{ \\bar\{\\phi\}_1, \\bar\{\\phi\}_2, \'85 , \\bar\{\\phi\}_\{t-1\}, \\bar\{\\phi\}_t\}\
\\end\{eqnarray\}\
-->\
\
Using kinematics and geometry of the robot over time, we can produce the posture image \\\\(I_\{k\}\\\\) which represents the swept void space at the position and orientation \\\\(X_\{k\}\\\\) in the global environment.}